{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seção 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-44d76fa8035e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Vetor de pesos inicial: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Alterações no vetor de Pesos: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitCountWeight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Numero de Epocas: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Vetor de Pesos no final: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightArray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Vetor de pesos inicial: \",n.weightArray)\n",
    "print(\"Alterações no vetor de Pesos: \", n.fitCountWeight)\n",
    "print(\"Numero de Epocas: \", n.epoch)\n",
    "print(\"Vetor de Pesos no final: \", np.around(n.weightArray,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vetor de pesos inicial:  **[ 0.43696957  0.25269746 -0.25452405]**\n",
    "\n",
    "&nbsp;\n",
    "Alterações no vetor de Pesos:  **58**\n",
    "\n",
    "&nbsp;\n",
    "Numero de Epocas:  **3**\n",
    "\n",
    "&nbsp;\n",
    "Vetor de Pesos no final:  **[ 337.3801 -337.1898   -0.8545]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acima temos o resultado apos a convergência do neurônio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico que gera todos os exemplos do conjunto de dados e a reta que separa as classes 0 na cor vermelha, e 1 na cor azul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figura 1](graph1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seção 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção foram realizados 100 treinos em 9 configurações, totalizando 900 treinos, ao final do treino de cada configuração, o vetor de pesos é exibido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Configuração: \", configs[k])\n",
    "print(\"Pesos da última iteração: \", n.weightArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "&nbsp;\n",
    "Configuração:  **[0.4, -100, 100]**\n",
    "\n",
    "&nbsp;\n",
    "Pesos da última iteração:  **[ 48.44955945  18.15808432 -36.16265305]**\n",
    "\n",
    "&nbsp;\n",
    "Configuração:  **[0.4, -1, 1]**\n",
    "\n",
    "&nbsp;\n",
    "Pesos da última iteração:  **[ 1.38298636  0.07744912 -0.59596041]**\n",
    "\n",
    "&nbsp;\n",
    "Configuração: **[0.4, -0.5, 0.5]**\n",
    "\n",
    "&nbsp;\n",
    "Pesos da última iteração:  **[ 0.88492064  0.1187579  -0.59190146]**\n",
    "\n",
    "&nbsp;\n",
    "Configuração:  **[0.1, -100, 100]**\n",
    "\n",
    "&nbsp;\n",
    "Pesos da última iteração:  **[27.48805085 -9.42930364 -7.6015573 ]**\n",
    "\n",
    "&nbsp;\n",
    "Configuração:  **[0.1, -1, 1]**\n",
    "\n",
    "&nbsp;\n",
    "Pesos da última iteração:  **[ 0.59743983 -0.07954027 -0.19805032]**\n",
    "\n",
    "&nbsp;\n",
    "Configuração:  **[0.1, -0.5, 0.5]**\n",
    "\n",
    "&nbsp;\n",
    "Pesos da última iteração:  **[ 0.32454427 -0.01094387 -0.18677542]**\n",
    "\n",
    "&nbsp;\n",
    "Configuração:  **[0.01, -100, 100]**\n",
    "\n",
    "&nbsp;\n",
    "Pesos da última iteração:  **[ 4.3967517   1.70475795 -3.31797817]**\n",
    "\n",
    "&nbsp;\n",
    "Configuração:  **[0.01, -1, 1]**\n",
    "\n",
    "&nbsp;\n",
    "Pesos da última iteração:  **[ 0.21774254 -0.06191229 -0.05750095]**\n",
    "\n",
    "&nbsp;\n",
    "Configuração:  **[0.01, -0.5, 0.5]**\n",
    "\n",
    "&nbsp;\n",
    "Pesos da última iteração:  **[ 0.0395797  -0.00287037 -0.01941535]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diante disso, o gráfico abaixo mostra os resultados de 100 treinamentos para cada configuração setada no neurônio perceptron, sendo o primeiro valor a taxa de aprendizado e os outros dois os intervalos mínimos e máximos para o peso, tais pesos foram gerados aleatoriamente entre estes intervalos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figura2](graph2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos Resultados de Média e Desvio Padrão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ajudar na análise de qual configuração é melhor, pior ou se são equivalentes, foi gerado a tabela abaixo contendo os valores de média e desvio padrão para a quantidade de ajustes no vetor de pesos e a quantidade de épocas necessárias até a conversão do neurônio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({ \"Config\": configs, \"Media_Ajustes\": fw_mean, \"Media_Epocas\": ep_mean, \"Desvio_Ajustes\": fw_std, \"Desvio_Epocas\": ep_std})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuração | Média Ajuste de Pesos | Média de Épocas | Desvio Padrão Ajuste de Pesos | Desvio Padrão de Épocas\n",
    ":---------: | :---------: | :---------: | :---------: | :---------:\n",
    "[0.4, -100, 100]    |     280.00    |    13.00   |   150.794496   |   7.009993  \n",
    "[0.4, -1, 1]        |     8.82      |    4.17    |    3.631474    |   1.349481  \n",
    "[0.4, -0.5, 0.5]    |     7.17      |    4.17    |    3.310755    |   1.077544  \n",
    "[0.1, -100, 100]    |     1068.58   |    41.15   |   614.377704   |   30.854619  \n",
    "[0.1, -1, 1]        |     15.58     |    4.12    |    8.513730    |   1.544539  \n",
    "[0.1, -0.5, 0.5]    |     10.16     |    4.25    |    5.401333    |   1.687454  \n",
    "[0.01, -100, 100]   |     11575.73  |    376.84  |   7061.931894  |   281.139066  \n",
    "[0.01, -1, 1]       |     129.87    |    7.19    |   73.974273    |   2.625624  \n",
    "[0.01, -0.5, 0.5]   |     63.68     |    4.91    |    40.659287   |   1.860618  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando-se os valores obtidos no gráfico, e sabendo-se que independente de quaisquer configuração, todas elas convergem para o acerto, como ja fora mostrado em todos os gráficos respectivos a cada configuração. Sendo assim, nota-se que a configuração **[0.01, -100, 100]** é a pior considerando suas médias e desvios, pois em termos de recursos computacionais e de convergência para o resultado correto esta foi a que demandou mais ajustes no vetor de pesos e mais épocas, isso se deve a sua baixa taxa de aprendizado e alta quantidade de valores possíveis para os pesos, tal fato se confirma quando analisamos também outras duas configurações, são elas **[0.1, -100, 100]** e **[0.4, -100, 100]**, mostrando que quando maior o intervalor que os pesos podem assumir de forma aleatória, maior é o tempo, ajustes e processamento que o neurônio demandará da máquina na qual esta sendo treinada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando a análise em relação a igualdade de configurações, nenhuma delas resulta em uma convergência exatamente equivalente a outra, porém elas são aproximadas, isto se mostra verdade quando analisamos os seus valores de média e desvio na tabela acima, como por exemplo as configurações **[0.4, -1, 1]** e **[0.4, -0.5, 0.5]** que possuem a média de ajustes próximas, a média de épocas igual e os desvios de ajustes de pesos e épocas aproximados. Por fim, em relação a uma melhor configuração e que leve a convergência mais rapidamente, temos a configuração **[0.4, -0.5, 0.5]**, a qual demandou menos ajustes e épocas como visto na tabela, porém isso de certa forma é relativo já que os pesos são gerados automaticamente, pode ser que haja valores entre -0.5 e 0.5 que demandem mais ajustes e épocas para convergir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seção 2.3 – Validação Holdout em Problema Não-Linearmente Separável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, consideramos o arquivo `dataHoldout.txt` para a entrada de dados. Em seguida, evidenciamos a partir de um gráfico que o problema não se tratava de um problema linearmente separável, isto é, não existe uma reta que separe as classes de saída do problema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figura3](graph3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, foi feita a divisão do dataset em conjuntos de treino e teste, com treino contendo 70% dos dados e teste contendo 30% dos dados, este processo faz parte da metodologia da validação Holdout. Após a divisão, o neurônio foi treinado por 100 épocas com o conjunto de treino, garantindo que a cada época os exemplos fossem utilizados em ordem aleatória. Após as 100 épocas, foi possível obter a seguinte reta de separação:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figura4](graph4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o treinamento, foi feita a matriz de confusão e a partir da mesma foram calculadas as métricas para determinação da qualidade do modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   | 1  | 0   |\n",
    "|---|----|-----|\n",
    "| 1 | 52 | 10  |\n",
    "| 0 | 2  | 157 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figura5](confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Métrica  | Valor |\n",
    "|--------------------|---- |\n",
    "| Acurácia | 0.9457 |\n",
    "| Precisão | 0.8387  | \n",
    "| Revocação | 0.963  | \n",
    "| F-Score | 0.8966  | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia é a métrica que apresenta a quantidade de vezes em que o modelo fez uma predição da forma correta, seja ela positiva ou negativa. Com um valor de 0.9457, podemos entender que uma previsão correta acontece em, aproximadamente, 94,,,% dos casos no conjunto de teste, o que é um valor considerado bom. Apesar de ser um bom indicativo, não é a única métrica relevante para a análise de um modelo, especialmente considerando se tratar de um dataset desbalanceado, com quantidade de saídas y = 0 muito superiores à saídas com y = 1, um clássico problema em que a acurácia não é uma boa métrica para análise.\n",
    "\n",
    "#### Quantidade de dados de y para valores 0 e 1:\n",
    "| Valor | Quantidade  |\n",
    "|:---|:----|\n",
    "| 0 | 600 |\n",
    "| 1 | 200  |\n",
    "\n",
    " A precisão determina o quanto os casos determinados como positivos pelo modelo eram realmente positivos. Com a precisão de 0.8387, conseguimos perceber cerca de 18% dos casos considerados positivos é previsto de forma errônea, o que para contextos em que a classificação positiva é crítica, como diagnóstico de doenças, onde um falso positivo pode ser fatal.\n",
    "\n",
    " O recall determina o quanto casos que eram positivos foram previstos como positivos pelo modelo. Com o recall de 0.963, conseguimos perceber que em aproximadamente 98% dos casos que eram positivos, o modelo consegue acertar a previsão, um valor bom para o modelo se tratando da previsão de casos positivos, tendo menos impacto em situações onde um caso falso negativo não implica em decisões críticas.\n",
    "\n",
    " O F1Score é a média harmônica entre a precisão e recall. Usamos a média harmônica pois a média aritmética é altamente influenciada por valores discrepantes. Quanto maior o valor do F1Score, mais balanceado e melhor é o modelo. O valor de F1Score é 0.8966, o que indica que o modelo tem bom desempenho para predição com os dados do conjunto de testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar dois gráficos com a solução provida pelo neurônio Perceptron, respectivamente com conjunto de treino e conjunto de testes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figura5](graph5.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
