{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Alunos:\n",
    "    David Cardoso Yonekura\n",
    "    Lucas da Silva Lima\n",
    "    Rafael Barbosa de Carvalho\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from neuron import Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "Configuração:  [[0.01, -100, 100], [0.01, -1, 1], [0.01, -0.5, 0.5]]\n",
      "[0.01, -1, 1] [0.01, -0.5, 0.5]\n",
      "[-0.29322959 -0.09065359  1.        ]\n",
      "[0.07988839 0.21101297 1.        ]\n",
      "[-0.07825563 -0.08083512  1.        ]\n",
      "[-0.46833414 -0.10620722  1.        ]\n",
      "[0.46304142 0.09405471 1.        ]\n",
      "[ 0.0114998  -0.05939114  1.        ]\n",
      "[0.27238274 0.18359397 1.        ]\n",
      "[0.08690974 0.00654493 1.        ]\n",
      "[0.0824192  0.00106606 1.        ]\n",
      "[-0.00940128 -0.10654841  1.        ]\n",
      "[ 0.05786483 -0.36451414  1.        ]\n",
      "[0.07028775 0.39056305 1.        ]\n",
      "[ 0.20013586 -0.41657686  1.        ]\n",
      "[-0.06282733 -0.32877261  1.        ]\n",
      "[-0.10391518  0.34638192  1.        ]\n",
      "[0.25527419 0.17171587 1.        ]\n",
      "[ 0.28382866 -0.00689202  1.        ]\n",
      "[0.34015635 0.06961302 1.        ]\n",
      "[-0.19908835  0.12926358  1.        ]\n",
      "[-0.03197237  0.16450966  1.        ]\n",
      "[-0.01465206  0.12680101  1.        ]\n",
      "[0.29560862 0.08406349 1.        ]\n",
      "[0.2367801  0.37531654 1.        ]\n",
      "[-0.09127282  0.28768163  1.        ]\n",
      "[-0.20389569  0.36597829  1.        ]\n",
      "[0.02409823 0.16569508 1.        ]\n",
      "[-0.04716837  0.19363929  1.        ]\n",
      "[-0.12350761  0.14385352  1.        ]\n",
      "[-0.04254102  0.26891466  1.        ]\n",
      "[ 0.08179828 -0.09956027  1.        ]\n",
      "[0.01035887 0.19358383 1.        ]\n",
      "[0.20300365 0.19595358 1.        ]\n",
      "[-0.29356844  0.00599321  1.        ]\n",
      "[-0.05039096 -0.43980938  1.        ]\n",
      "[-0.25504586  0.25995271  1.        ]\n",
      "[0.32606995 0.33196305 1.        ]\n",
      "[0.2123362  0.02517371 1.        ]\n",
      "[0.28066172 0.13031361 1.        ]\n",
      "[0.26394155 0.32750883 1.        ]\n",
      "[-0.07617946  0.02320954  1.        ]\n",
      "[-0.05049252 -0.25006668  1.        ]\n",
      "[0.12020386 0.40989806 1.        ]\n",
      "[-0.22671361  0.21841371  1.        ]\n",
      "[0.30399699 0.00645548 1.        ]\n",
      "[0.09743172 0.24002227 1.        ]\n",
      "[ 0.40646314 -0.16905173  1.        ]\n",
      "[-0.62237404  0.12119507  1.        ]\n",
      "[-0.18777062  0.42687831  1.        ]\n",
      "[0.08097161 0.30854443 1.        ]\n",
      "[0.25776183 0.03455125 1.        ]\n",
      "[ 0.06627455 -0.26057051  1.        ]\n",
      "[-0.0054924  -0.30231266  1.        ]\n",
      "[ 0.05824952 -0.07760549  1.        ]\n",
      "[0.04253339 0.4469942  1.        ]\n",
      "[0.19031887 0.13251078 1.        ]\n",
      "[-0.17369552 -0.02572443  1.        ]\n",
      "[ 0.10170691 -0.02426339  1.        ]\n",
      "[-0.14967201 -0.19512452  1.        ]\n",
      "[-0.10038537 -0.60750339  1.        ]\n",
      "[0.15371662 0.27078076 1.        ]\n",
      "[0.19110701 0.2105866  1.        ]\n",
      "[-0.0150527  -0.12832773  1.        ]\n",
      "[-0.11163154  0.00851976  1.        ]\n",
      "[0.00359837 0.18216627 1.        ]\n",
      "[0.15252857 0.01744889 1.        ]\n",
      "[-0.51802769  0.04584568  1.        ]\n",
      "[-0.31482467  0.02071152  1.        ]\n",
      "[-0.07722405  0.18953338  1.        ]\n",
      "[ 0.03645874 -0.23372151  1.        ]\n",
      "[-0.0294872   0.13216526  1.        ]\n",
      "[-0.01442025 -0.02745483  1.        ]\n",
      "[0.09509565 0.35550407 1.        ]\n",
      "[-0.0180137   0.39719079  1.        ]\n",
      "[-0.02677506  0.19158953  1.        ]\n",
      "[0.17537603 0.17826557 1.        ]\n",
      "[-0.20009509  0.37511566  1.        ]\n",
      "[-0.02228633  0.03087271  1.        ]\n",
      "[0.08298076 0.12868493 1.        ]\n",
      "[ 0.22245222 -0.2466912   1.        ]\n",
      "[ 0.04322791 -0.0461912   1.        ]\n",
      "[-0.22615337  0.1493509   1.        ]\n",
      "[ 0.48892004 -0.13726797  1.        ]\n",
      "[0.36729907 0.07514918 1.        ]\n",
      "[-0.00474636  0.09826743  1.        ]\n",
      "[-0.28552876 -0.16910219  1.        ]\n",
      "[-0.16562461  0.00357497  1.        ]\n",
      "[ 0.45659077 -0.31018866  1.        ]\n",
      "[-0.02215321  0.00269713  1.        ]\n",
      "[-0.21748562  0.03151915  1.        ]\n",
      "[-0.10259311 -0.06961393  1.        ]\n",
      "[ 0.03195638 -0.10251385  1.        ]\n",
      "[ 0.26072056 -0.14729552  1.        ]\n",
      "[-0.21442938  0.00797897  1.        ]\n",
      "[-0.26329819  0.12863801  1.        ]\n",
      "[-0.15506501  0.12410647  1.        ]\n",
      "[ 0.08948218 -0.22242627  1.        ]\n",
      "[-0.06865786 -0.18994482  1.        ]\n",
      "[-0.08879326 -0.07108222  1.        ]\n",
      "[0.1196882  0.08875686 1.        ]\n",
      "[-0.0907412  -0.05805187  1.        ]\n",
      "[-0.37025595 -0.19697218  1.        ]\n",
      "[ 0.23012362 -0.26821715  1.        ]\n",
      "[-0.3001711   0.32724374  1.        ]\n",
      "[ 0.32622018 -0.00707064  1.        ]\n",
      "[0.14927021 0.30009393 1.        ]\n",
      "[0.03416729 0.17169338 1.        ]\n",
      "[ 0.00976696 -0.02053641  1.        ]\n",
      "[-0.18164836  0.0789158   1.        ]\n",
      "[-0.027351   -0.14271275  1.        ]\n",
      "[-0.12717344 -0.01477397  1.        ]\n",
      "[-0.32030378 -0.05453506  1.        ]\n",
      "[ 0.15207387 -0.1526586   1.        ]\n",
      "[0.16775772 0.22831062 1.        ]\n",
      "[0.07413358 0.09435939 1.        ]\n",
      "[0.07180622 0.49468375 1.        ]\n",
      "[-0.06775393 -0.12753433  1.        ]\n",
      "[0.01272533 0.20346543 1.        ]\n",
      "[-0.0458408  0.0510611  1.       ]\n",
      "[0.0806008  0.02952231 1.        ]\n",
      "[ 0.1408635  -0.30766359  1.        ]\n",
      "[-0.29330698 -0.055651    1.        ]\n",
      "[0.26482475 0.03523472 1.        ]\n",
      "[ 0.25843371 -0.12301855  1.        ]\n",
      "[0.00394505 0.1408983  1.        ]\n",
      "[0.3509719  0.01024045 1.        ]\n",
      "[-0.09643162 -0.23454603  1.        ]\n",
      "[0.30158872 0.27389296 1.        ]\n",
      "[0.09475184 0.00442865 1.        ]\n",
      "[-0.05640173  0.06447469  1.        ]\n",
      "[-0.04162565  0.12822745  1.        ]\n",
      "[-0.24470797  0.30017534  1.        ]\n",
      "[ 0.00531634 -0.05266985  1.        ]\n",
      "[0.12052833 0.52761443 1.        ]\n",
      "[-0.13057195 -0.14399009  1.        ]\n",
      "[ 0.31024232 -0.13097232  1.        ]\n",
      "[ 0.08562892 -0.17567279  1.        ]\n",
      "[-0.0031101   0.18965456  1.        ]\n",
      "[-0.10074294 -0.31860073  1.        ]\n",
      "[0.36754371 0.0090821  1.        ]\n",
      "[-0.26424484 -0.21427883  1.        ]\n",
      "[ 0.07936731 -0.18897409  1.        ]\n",
      "[ 0.19559446 -0.36660313  1.        ]\n",
      "[-0.08268563 -0.2708728   1.        ]\n",
      "[ 0.35751084 -0.30883258  1.        ]\n",
      "[-0.2175649  -0.24798023  1.        ]\n",
      "[0.21675147 0.54097717 1.        ]\n",
      "[2.76838226e-01 6.14786659e-04 1.00000000e+00]\n",
      "[-0.24300515  0.15164356  1.        ]\n",
      "[ 0.24709879 -0.16289625  1.        ]\n",
      "[ 0.06285892 -0.224167    1.        ]\n",
      "[0.04070169 0.19547759 1.        ]\n",
      "[-0.26652617 -0.02689509  1.        ]\n",
      "[-0.46980094 -0.20331005  1.        ]\n",
      "[-0.11966564 -0.05239423  1.        ]\n",
      "[ 0.01047289 -0.025923    1.        ]\n",
      "[ 0.17261639 -0.23042727  1.        ]\n",
      "[-0.19649707 -0.11955184  1.        ]\n",
      "[0.1460631 0.1776204 1.       ]\n",
      "[-0.0547258  -0.11131214  1.        ]\n",
      "[ 0.66026778 -0.21191075  1.        ]\n",
      "[0.14347628 0.25927685 1.        ]\n",
      "[-0.52664262 -0.03855007  1.        ]\n",
      "[-0.08041492 -0.18693755  1.        ]\n",
      "[-0.31310084  0.27736732  1.        ]\n",
      "[ 0.0748692  -0.03487411  1.        ]\n",
      "[0.30687156 0.11512797 1.        ]\n",
      "[0.00842475 0.20229318 1.        ]\n",
      "[0.19643799 0.20349331 1.        ]\n",
      "[-0.11168935  0.10246164  1.        ]\n",
      "[-0.23436994  0.03978647  1.        ]\n",
      "[0.02913203 0.02879716 1.        ]\n",
      "[ 0.07337792 -0.05966064  1.        ]\n",
      "[-0.10671724 -0.00445963  1.        ]\n",
      "[0.07785338 0.2471932  1.        ]\n",
      "[-0.06856801  0.16646269  1.        ]\n",
      "[-0.29123621  0.11011622  1.        ]\n",
      "[ 0.23694238 -0.29150454  1.        ]\n",
      "[ 0.05814864 -0.23049015  1.        ]\n",
      "[-0.23593942  0.18670953  1.        ]\n",
      "[ 0.12177941 -0.25516114  1.        ]\n",
      "[-0.38616416  0.00437877  1.        ]\n",
      "[ 0.19028998 -0.01032709  1.        ]\n",
      "[0.37222961 0.06930466 1.        ]\n",
      "[0.04070907 0.1350255  1.        ]\n",
      "[-0.06835829 -0.22927445  1.        ]\n",
      "[ 0.27835023 -0.27168854  1.        ]\n",
      "[-0.02088851  0.14046572  1.        ]\n",
      "[0.21265355 0.2789915  1.        ]\n",
      "[ 0.01004054 -0.29692638  1.        ]\n",
      "[ 0.31474715 -0.09874167  1.        ]\n",
      "[-0.1753094  -0.26744178  1.        ]\n",
      "[-0.26924602  0.32950513  1.        ]\n",
      "[-0.33000132  0.07234854  1.        ]\n",
      "[-0.05213949 -0.05768201  1.        ]\n",
      "[-0.03883705  0.13043894  1.        ]\n",
      "[-0.21901569 -0.28125484  1.        ]\n",
      "[-0.04347767 -0.18293735  1.        ]\n",
      "[ 0.10182486 -0.21442921  1.        ]\n",
      "[-0.2502875   0.13876078  1.        ]\n",
      "[0.24564694 0.0185413  1.        ]\n",
      "[0.40713655 1.3881116  1.        ]\n",
      "[-0.2622912   1.07843455  1.        ]\n",
      "0.0\n",
      "1\n",
      "[-0.2622912   1.07843455  1.        ]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'numpy.float64'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-133db4f14b06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Configuração: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun100epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\redes-neurais\\perceptron-redesNeurais2020\\src\\neuron.py\u001b[0m in \u001b[0;36mrun100epochs\u001b[1;34m(self, arrayX, arrayY)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrayX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrayX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdateWeightArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrayY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculateActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrayX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marrayX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitCountWeight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweightArray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\redes-neurais\\perceptron-redesNeurais2020\\src\\neuron.py\u001b[0m in \u001b[0;36mupdateWeightArray\u001b[1;34m(self, expectValue, obtainedValue, input_)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobtainedValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mauxData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpectValue\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mobtainedValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweightArray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweightArray\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mauxData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'numpy.float64'"
     ]
    }
   ],
   "source": [
    "with open('data/dataHoldout.txt', 'rb') as file:\n",
    "    auxFile = file.read()\n",
    "\n",
    "\n",
    "dataHoldout = np.frombuffer(auxFile)\n",
    "dataHoldout.resize((int(len(dataHoldout)/3)), 3)\n",
    "\n",
    "X = dataHoldout[...,0:2] #[[x01,x02], ...]\n",
    "y = dataHoldout[...,2] #[[yd0], [yd1], ...]\n",
    "print(y.dtype)\n",
    "# #adicionando x_0 no x(n)\n",
    "X = np.insert(X, 2, 1, axis=1)\n",
    "#instanciando o neuronio, inserindo apenas a taxa de aprendizado\n",
    "# e os intervalos superior e inferior dos pesos\n",
    "config= [[0.01,-100,100], [0.01,-1,1], [0.01,-0.5,0.5]]\n",
    "fitWeight = []\n",
    "epoch = []\n",
    "print(\"Configuração: \", config)\n",
    "n = Neuron(config[0], config[1], config[2])\n",
    "n.run100epochs(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.001),\n",
    "                     np.arange(y_min, y_max, 0.001))\n",
    "\n",
    "f, axarr = plt.subplots(1, 1, sharex='col', sharey='row', figsize=(10, 8))\n",
    "color = np.where(y == 0, 'r', 'b')\n",
    "\n",
    "for idx, clf, tt in zip([[0,0]],\n",
    "                        [n],\n",
    "                        ['logistic regression']):\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = np.array(Z)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    axarr.contourf(xx, yy, Z, alpha=0.2,cmap='Greys')\n",
    "    axarr.scatter(X[:, 0], X[:, 1], c=color, s=20, edgecolor='k',cmap='Greys')\n",
    "    axarr.set_title(tt)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# f.savefig('gaph2.png')\n",
    "# plt.close(f)\n",
    "\n",
    "#exportando a figura para por no markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
